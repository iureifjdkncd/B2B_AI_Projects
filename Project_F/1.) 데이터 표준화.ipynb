{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "630d1350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import glob \n",
    "from tqdm import tqdm\n",
    "from itertools import repeat\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', None)\n",
    "import datetime\n",
    "from datetime import datetime,timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, StratifiedKFold, KFold ,GridSearchCV ,cross_validate\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier,AdaBoostClassifier,IsolationForest,StackingClassifier,HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score,balanced_accuracy_score,precision_score,recall_score,confusion_matrix,f1_score,fbeta_score,roc_auc_score,classification_report,make_scorer,balanced_accuracy_score\n",
    "from mlxtend.classifier import StackingClassifier,StackingCVClassifier\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler,MinMaxScaler,RobustScaler,Binarizer\n",
    "from imblearn.over_sampling import SMOTE,ADASYN,BorderlineSMOTE,SVMSMOTE\n",
    "from imblearn.combine import SMOTEENN,SMOTETomek\n",
    "from imblearn.under_sampling import RandomUnderSampler,NearMiss,TomekLinks,CondensedNearestNeighbour,EditedNearestNeighbours\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee616017-ba98-4357-8776-04cf7f366d83",
   "metadata": {},
   "source": [
    "#### 1.) 데이터 기초 전처리 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "438ed710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_production(i):\n",
    "    if i < 39:\n",
    "        #### 샘플(배치) 데이터 \n",
    "        if i == 8:\n",
    "            ### N236072024 배치 생산 데이터 --> 카운트 중간지점부터 재개 [ 이전 생산량 오류로 판명 --> 삭제 ]\n",
    "            df_sample = pd.read_csv(df_list_2[i])\n",
    "            df_sample = df_sample[df_sample['일시'] >= '2023-06-07 15:43:16'].reset_index(drop=True)\n",
    "            df_sample['일시'] = pd.to_datetime(df_sample['일시'])\n",
    "            df_sample['BatchName'] = df_list_2[i][-14:-4]     \n",
    "        elif i == 19:\n",
    "            df_sample = pd.read_csv(df_list_2[i])\n",
    "            #print('20번 배치  2023-06-15 16:28:13 ~ 2023-06-15 16:28:55 ==> 2001 다음 2080')\n",
    "            df_sample = df_sample[df_sample['투입수량'] != 2001].reset_index(drop=True)\n",
    "            df_sample['일시'] = pd.to_datetime(df_sample['일시'])\n",
    "            df_sample['BatchName'] = df_list_2[i][-14:-4]          \n",
    "        elif i == 24:\n",
    "            df_sample = pd.read_csv(df_list_2[i])\n",
    "            #print('25번 배치  2023-06-16 23:55:10 ~ 2023-06-16 23:57:47 ==> 17859 다음 18145')\n",
    "            df_sample = df_sample[df_sample['투입수량'] != 17859].reset_index(drop=True)\n",
    "            df_sample['일시'] = pd.to_datetime(df_sample['일시'])\n",
    "            df_sample['BatchName'] = df_list_2[i][-14:-4]        \n",
    "        elif i ==29:\n",
    "            df_sample = pd.read_csv(df_list_2[i])\n",
    "            #print('30번 배치  2023-06-17 23:57:24 ~ 2023-06-18 00:00:01 ==> 25197 다음 25483')\n",
    "            df_sample = df_sample[df_sample['투입수량'] != 25197].reset_index(drop=True)\n",
    "            df_sample['일시'] = pd.to_datetime(df_sample['일시'])\n",
    "            df_sample['BatchName'] = df_list_2[i][-14:-4]           \n",
    "        elif i == 21:\n",
    "            #### 샘플데이터 22번 --> 인코딩 cp949 별도 & 초단위 시간 별도 적용 필요\n",
    "            df_sample = pd.read_csv(df_list_2[i],encoding='cp949')\n",
    "            df_sample['일시'] = pd.to_datetime(df_sample['일시'])\n",
    "            df_sample['일시'] += pd.TimedeltaIndex(df_sample.groupby('일시').cumcount(), unit='s')\n",
    "            df_sample['BatchName'] = df_list_2[i][-14:-4]\n",
    "        else:\n",
    "            ### 나름 정상 생산 \n",
    "            df_sample = pd.read_csv(df_list_2[i])\n",
    "            df_sample['일시'] = pd.to_datetime(df_sample['일시'])\n",
    "            df_sample['BatchName'] = df_list_2[i][-14:-4]\n",
    "    else:\n",
    "        #### 샘플데이터 40번 --> 인코딩 cp949 & 초단위 시간 별도 적용 필요  \n",
    "        df_sample = pd.read_csv(df_list_2[i],encoding='cp949')\n",
    "        df_sample = df_sample.rename(columns={'?쇱떆':'일시'})\n",
    "        df_sample['일시'] = pd.to_datetime(df_sample['일시'])\n",
    "        df_sample['일시'] += pd.TimedeltaIndex(df_sample.groupby('일시').cumcount(), unit='s')\n",
    "        df_sample = df_sample[df_sample['일시'] != '2023-06-28 02:35:16'].reset_index(drop=True)\n",
    "        df_sample['BatchName'] = df_list_2[i][-14:-4]     \n",
    "    #### Column & 데이터 정보 필터링\n",
    "    df = df_sample\n",
    "    df_inputcols = df.drop(['일시','투입수량','양품수량','불량수량','BatchName'],axis=1).head(1)\n",
    "    df_tagnames = df_inputcols.T.reset_index()[['index']].rename(columns={'index':'태그명'})\n",
    "    df_tagnames_list = df_tagnames['태그명'].tolist()\n",
    "    \n",
    "    #### 태그정보 통합\n",
    "    #df_info = pd.read_excel('C:/Users/sangb/OneDrive/바탕 화면/LS엠트론/사출데이터/사출데이터/INM005 tag list.xlsx')\n",
    "    df_info = pd.read_excel('C:/Users/user/Desktop/데이터분석 프로젝트/LS엠트론/사출데이터/INM005 tag list.xlsx')\n",
    "    df_info = df_info[df_info['태그명'].isin(df_tagnames_list) == True]\n",
    "    df_info = df_info.dropna(axis=1).reset_index(drop=True)\n",
    "    #df_info_2 = pd.read_csv('C:/Users/sangb/OneDrive/바탕 화면/LS엠트론/사출데이터/사출데이터/태그 정리_v2.csv',encoding='cp949')\n",
    "    df_info_2 =  pd.read_csv('C:/Users/user/Desktop/데이터분석 프로젝트/LS엠트론/사출데이터/태그 정리_v2.csv',encoding='cp949')\n",
    "    df_taglist = pd.merge(df_info,df_info_2[['태그설명','구분']],on='태그설명',how='inner').drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    #### 태그설명 완료 데이터 \n",
    "    df_tag = df_sample.drop(['BatchName','일시','투입수량','양품수량','불량수량'],axis=1)\n",
    "    df_nontag = df_sample[['BatchName','일시','투입수량','양품수량','불량수량']]\n",
    "    df_tag.columns = df_taglist['태그설명'].tolist()\n",
    "    df_sample['사출기'] = 'INM005 05호기(수평)'\n",
    "    df_added = pd.concat([df_sample['사출기'],df_nontag,df_tag],axis=1)\n",
    "    \n",
    "    #### 기존 배치 단위 데이터에서 누적투입/양품/불량수량 동시 = 0 제외 ==> 생산 대기중 가정 \n",
    "    df_existing_counts = df_added[(df_added['투입수량'] !=0) & (df_added['양품수량'] !=0)]\n",
    "    \n",
    "    #### 배치 데이터 인덱스 부여 \n",
    "    df_production = df_existing_counts\n",
    "    df_production = df_production.reset_index(drop=True)\n",
    "    df_production['sampledata_index'] = i+1\n",
    "    df_production = df_production.rename(columns={'일시':'생산시간'})\n",
    "    return df_production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1378aa-ce28-4d4f-afa5-22bcc9a02135",
   "metadata": {},
   "source": [
    "#### 2.) 생산데이터 표준화 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d1aa41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycletime_indexing(i):\n",
    "    start = 1\n",
    "    integer = 0\n",
    "    decimal = 0\n",
    "    group_number = 0\n",
    "    lag = 2 # lag custom 지정 가능 \n",
    "    result = []\n",
    "    result_group_number = []\n",
    "    total_df = pd.DataFrame()\n",
    "    df = load_production(i) # cycletime 3.6 ~ 5.9초만 활용 \n",
    "    df = df[(df['사출기 : 실적표시:사이클시간_Actual_v.:Cycle_time'] >=3)&(df['사출기 : 실적표시:사이클시간_Actual_v.:Cycle_time'] <6)]\n",
    "    df = df.reset_index(drop=True)\n",
    "    # 수량 한정 시차 이동 \n",
    "    count_shift = df[['투입수량','양품수량','불량수량']].shift(lag) # lag 0 --> 시차이동 X \n",
    "    df[['투입수량','양품수량','불량수량']] = count_shift\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    for n, i in enumerate(range(len(df))): \n",
    "        if start == 1:   \n",
    "            integer, decimal_point = str(df.iloc[i]['사출기 : 실적표시:사이클시간_Actual_v.:Cycle_time']).split('.')\n",
    "            integer, decimal_point = int(integer), float(decimal_point)\n",
    "            if decimal >= 1:\n",
    "                decimal -= 1\n",
    "                integer += 1\n",
    "            if n == 0:\n",
    "                result_group_number.append(group_number)\n",
    "                result.append(df.iloc[i])\n",
    "                start += 1\n",
    "                decimal = decimal+ decimal_point*0.1\n",
    "            else:\n",
    "                result_group_number.append(group_number)\n",
    "                group_number+=1\n",
    "                start += 1\n",
    "                result_group_number.append(group_number)\n",
    "                result.append(df.iloc[i])\n",
    "                result.append(df.iloc[i])\n",
    "                decimal = decimal+ decimal_point*0.1\n",
    "        else:\n",
    "            result_group_number.append(group_number)\n",
    "            result.append(df.iloc[i])\n",
    "            start += 1\n",
    "            if start < integer: continue\n",
    "            else: start -= integer\n",
    "    df1 = pd.DataFrame(result, columns = df.columns)\n",
    "    df1['group'] = result_group_number\n",
    "    df1 = df1[df1.group != group_number]\n",
    "    total_df = pd.concat([total_df,df1])\n",
    "    return total_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71c76a2-be60-453e-a184-ecf0f7e03aca",
   "metadata": {},
   "source": [
    "#### 3.) 데이터 추가 전처리 함수1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d304794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_production():\n",
    "    #### 1.) 데이터 통합 \n",
    "    dfs = []\n",
    "    for i in data_list:\n",
    "        total_df = cycletime_indexing(i)\n",
    "        print('Data No.',i+1,' ==> Add CycleTime_Index',' ',len(total_df))\n",
    "        dfs.append(total_df) \n",
    "    df_concat = pd.concat(dfs).reset_index(drop=True)\n",
    "    info_cols = df_concat.columns[:6].tolist() + df_concat.columns[-2:].tolist()\n",
    "    input_cols = df_concat.columns[6:-2].tolist()\n",
    "    production = df_concat[info_cols + input_cols]\n",
    "\n",
    "    #### 2.) Setting & Actual 변수 분리 \n",
    "    df_inputcols = production[input_cols].head(1)\n",
    "    df_tagnames = df_inputcols.T.reset_index()[['index']].rename(columns={'index':'태그명'})\n",
    "    df_tagnames_list = df_tagnames['태그명'].tolist()\n",
    "    df_info = pd.read_excel('C:/Users/user/Desktop/데이터분석 프로젝트/LS엠트론/사출데이터/INM005 tag list.xlsx')\n",
    "    df_info = df_info[df_info['태그설명'].isin(df_tagnames_list) == True]\n",
    "    df_info = df_info.dropna(axis=1).reset_index(drop=True)\n",
    "    df_info_2 = pd.read_csv('C:/Users/user/Desktop/데이터분석 프로젝트/LS엠트론/사출데이터/태그 정리_v2.csv',encoding='cp949')\n",
    "    df_taglist = pd.merge(df_info,df_info_2[['태그설명','구분']],on='태그설명',how='inner').drop_duplicates().reset_index(drop=True)\n",
    "    df_settings = []\n",
    "    for j in range(0,len(df_taglist)):\n",
    "        if 'sv' in df_taglist['구분'].iloc[j]:\n",
    "            df_settings.append('True')\n",
    "        elif 'SV' in df_taglist['구분'].iloc[j]:\n",
    "            df_settings.append('True')\n",
    "        else:\n",
    "            df_settings.append('False')\n",
    "    df_taglist['is_setting'] = pd.DataFrame(df_settings) \n",
    "    tag_divided_info = df_taglist[df_taglist['is_setting'] == 'False'][['태그설명','구분']]\n",
    "    setting_cols = df_taglist[df_taglist['is_setting'] == 'True']['태그설명'].tolist()\n",
    "    actual_cols = df_taglist[df_taglist['is_setting'] == 'False']['태그설명'].tolist()\n",
    "\n",
    "    #### 3.) Setting값  제거  \n",
    "    production = production[info_cols + actual_cols]\n",
    "\n",
    "    #### 4.) 통합 데이터 기준 총변동 1회인 Actual값 사전 제거 [ 모든 데이터에서 같은 조건의 수치를 가진 변수 ]\n",
    "    col_count = pd.DataFrame(production[actual_cols].nunique()).sort_values(by=0,ascending=True).reset_index().rename(columns={'index':'태그설명',0:'Count'})\n",
    "    production = production[production.columns[:8].tolist() + col_count[col_count['Count'] >1]['태그설명'].tolist()]\n",
    "    print('\\n')\n",
    "    print('Setting Values ==>',len(setting_cols))\n",
    "    print('Original Actual Values =',len(actual_cols),' ','==>  Cut Actual Values=',len(production.columns[8:].tolist()))\n",
    "    return production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8f00d5-ee36-4ac1-aca8-5f8df9712000",
   "metadata": {},
   "source": [
    "#### 4.) 데이터 추가 전처리 함수2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cde38a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def production_filter(i):\n",
    "    production_connect = production\n",
    "    production_connect = production_connect.rename(columns={'group':'cycletime_index'})\n",
    "    \n",
    "    #### 생산데이터 선택 ==> Actual 입력변수 & CycleTime_Index 정의 \n",
    "    sampledata = production_connect[production_connect['sampledata_index']== i+1]\n",
    "    actual_cols_list = production_connect.columns[8:].tolist()\n",
    "    cycletime_index_list = sampledata['cycletime_index'].unique().tolist()\n",
    "    \n",
    "    #### 1.) 투입 생산수량이 증가하지 않는 부분행 데이터 전부 제거 \n",
    "    quantity_increase = []\n",
    "    for k in cycletime_index_list:\n",
    "        sampledata_cycleindex =  sampledata[sampledata['cycletime_index']==k]\n",
    "        cycletime_index = sampledata_cycleindex['cycletime_index'].unique()[0]\n",
    "        if sampledata_cycleindex['투입수량'].nunique() !=1:\n",
    "            quantity_increase.append(cycletime_index)\n",
    "    production_cut = sampledata[sampledata['cycletime_index'].isin(quantity_increase) == True]\n",
    "    production_cut = production_cut.reset_index(drop=True)\n",
    "    print('투입수량 증가하는 CycleTime_Index 식별 ==> Data No.',i+1,'',production_cut['BatchName'].unique()[0],'',len(production_cut),'행')\n",
    "    return production_cut\n",
    "\n",
    "def preprocess_filter():\n",
    "    df_filtered = []\n",
    "    for i in data_list:\n",
    "        production_cut = production_filter(i)\n",
    "        if len(production_cut) !=0:    \n",
    "            df_filtered.append(production_cut)\n",
    "    production_cut_1 = pd.concat(df_filtered).reset_index(drop=True)\n",
    "    \n",
    "    #### 총변동 1회인 Actual값 사전 제거 [ 모든 데이터에서 같은 조건의 수치를 가진 변수 ]\n",
    "    actual_cols = production_cut_1.columns[8:].tolist()\n",
    "    col_count = pd.DataFrame(production_cut_1[actual_cols].nunique()).sort_values(by=0,ascending=True).reset_index().rename(columns={'index':'태그설명',0:'Count'})\n",
    "    production_filtered = production_cut_1[production_cut_1.columns[:8].tolist() + col_count[col_count['Count'] >1]['태그설명'].tolist()]\n",
    "    return production_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7085319c-e0cc-47c7-9828-4e9719aeee88",
   "metadata": {},
   "source": [
    "#### 5.) 데이터 추가 전처리 함수3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20c0e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_selection(i):\n",
    "    select_data = production_filtered[production_filtered['sampledata_index'] == i+1]\n",
    "    return select_data\n",
    "\n",
    "def change_detection(j):\n",
    "    select_data = data_selection(i)\n",
    "    input_cols = select_data.columns[8:].tolist()\n",
    "    split_cycletime = select_data[select_data['cycletime_index']==j].reset_index(drop=True)\n",
    "    split_cycletime_inputs = split_cycletime[input_cols]\n",
    "    check_all_unique = split_cycletime_inputs.loc[:,split_cycletime_inputs.apply(pd.Series.nunique) != 1]\n",
    "    change_detect = len(check_all_unique.columns.tolist())\n",
    "    if change_detect >0:\n",
    "        split_cycletime['Change_Detection'] = 'True'\n",
    "    else:\n",
    "        split_cycletime['Change_Detection'] = 'False'     \n",
    "    return split_cycletime\n",
    "\n",
    "def add_change_detection(i):\n",
    "    select_data = data_selection(i)\n",
    "    cycletime_index = select_data['cycletime_index'].unique().tolist()\n",
    "    dfs = []\n",
    "    for j in cycletime_index:\n",
    "        split_cycletime = change_detection(j)\n",
    "        dfs.append(split_cycletime)\n",
    "    production_sample = pd.concat(dfs).reset_index(drop=True)\n",
    "    return production_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6209c44d-c1f3-47aa-8de8-27702bf867d5",
   "metadata": {},
   "source": [
    "#### 6.) 생산데이터 최종  분석용 집계함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "244ceb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby(i):\n",
    "    select_data = production_added[production_added['sampledata_index']==i+1]\n",
    "    input_counts = ['투입수량','양품수량','불량수량']\n",
    "    input_cols = select_data.columns[9:-5].tolist()\n",
    "    info_cols = ['BatchName','sampledata_index']\n",
    "    time_col = ['생산시간']\n",
    "\n",
    "    #### 정보 나열 \n",
    "    df_info = select_data.groupby('cycletime_index')[info_cols].first()\n",
    "\n",
    "    #### CyleTime_Index당 수량 증가량 \n",
    "    count_first = select_data.groupby('cycletime_index')[input_counts].first()\n",
    "    count_last = select_data.groupby('cycletime_index')[input_counts].last()\n",
    "    inputcount_increments = count_last - count_first\n",
    "    \n",
    "    #### CycleTime_Index당 누적수량 \n",
    "    #count_max = select_data.groupby('cycletime_index')[input_counts].max()\n",
    "    #count_max.columns = count_max.columns + \"(누적)\"\n",
    "\n",
    "    #### CycleTime_Index당 시작 ~ 종료 시점 \n",
    "    cycle_start = select_data.groupby('cycletime_index')[time_col].first().rename(columns={'생산시간':'생산시작'})\n",
    "    cycle_last = select_data.groupby('cycletime_index')[time_col].last().rename(columns={'생산시간':'생산종료'})\n",
    "    df_time = pd.concat([cycle_start,cycle_last],axis=1)\n",
    "\n",
    "    #### CycleTime_Index당 통계량 \n",
    "    #input_min = select_data.groupby('cycletime_index')[input_cols].min()\n",
    "    #input_min.columns = input_min.columns + \"_Min\"\n",
    "    \n",
    "    #input_max = select_data.groupby('cycletime_index')[input_cols].max()\n",
    "    #input_max.columns = input_max.columns + \"_Max\"\n",
    "    \n",
    "    input_mean = select_data.groupby('cycletime_index')[input_cols].mean()\n",
    "    input_mean.columns = input_mean.columns + \"_Mean\"\n",
    "\n",
    "    #### CycleTime_Index당 Change Detection \n",
    "    change_detection = select_data.groupby('cycletime_index')['Change_Detection'].agg(lambda x:x.value_counts().index[0])\n",
    "    df_groupby = pd.concat([df_info,df_time,inputcount_increments,input_mean,change_detection],axis=1)\n",
    "    \n",
    "    #### CycleTime_Index당 집계된 투입수량 ==8 [ 우선 적용 ]\n",
    "    df_groupby = df_groupby[df_groupby['투입수량'] ==8].reset_index(drop=True)\n",
    "    return df_groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c107201",
   "metadata": {},
   "source": [
    "#### 7.) 생산데이터 업로드\n",
    "- 배치 오류/ 투입수량 Count 수치 이상 제거 \n",
    "- Target 시차 이동 설정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45c9057f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생산 샘플 csv 개수 --> 40\n"
     ]
    }
   ],
   "source": [
    "#### 활용할 배치 데이터 \n",
    "data_list = [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39]\n",
    "#### 데이터 저장 경로 설정 \n",
    "path = 'C:/Users/user/Desktop/데이터분석 프로젝트/LS엠트론/사출데이터/CSV 사출데이터'\n",
    "df_list_2 = glob.glob(path +'\\*.csv') \n",
    "print('생산 샘플 csv 개수 -->',len(df_list_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35ec952e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BatchName</th>\n",
       "      <th>생산시간</th>\n",
       "      <th>투입수량</th>\n",
       "      <th>양품수량</th>\n",
       "      <th>불량수량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N236012024</td>\n",
       "      <td>2023-06-01 19:31:29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N236012024</td>\n",
       "      <td>2023-06-01 19:31:30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N236012024</td>\n",
       "      <td>2023-06-01 19:31:31</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N236012024</td>\n",
       "      <td>2023-06-01 19:31:32</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N236012024</td>\n",
       "      <td>2023-06-01 19:31:33</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13467</th>\n",
       "      <td>N236012024</td>\n",
       "      <td>2023-06-01 23:15:56</td>\n",
       "      <td>25807.0</td>\n",
       "      <td>25081.0</td>\n",
       "      <td>726.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13468</th>\n",
       "      <td>N236012024</td>\n",
       "      <td>2023-06-01 23:15:57</td>\n",
       "      <td>25807.0</td>\n",
       "      <td>25081.0</td>\n",
       "      <td>726.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13469</th>\n",
       "      <td>N236012024</td>\n",
       "      <td>2023-06-01 23:15:58</td>\n",
       "      <td>25807.0</td>\n",
       "      <td>25081.0</td>\n",
       "      <td>726.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13470</th>\n",
       "      <td>N236012024</td>\n",
       "      <td>2023-06-01 23:15:59</td>\n",
       "      <td>25807.0</td>\n",
       "      <td>25081.0</td>\n",
       "      <td>726.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13471</th>\n",
       "      <td>N236012024</td>\n",
       "      <td>2023-06-01 23:16:00</td>\n",
       "      <td>25807.0</td>\n",
       "      <td>25081.0</td>\n",
       "      <td>726.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13472 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BatchName                생산시간     투입수량     양품수량   불량수량\n",
       "0      N236012024 2023-06-01 19:31:29      1.0      1.0    0.0\n",
       "1      N236012024 2023-06-01 19:31:30      4.0      4.0    0.0\n",
       "2      N236012024 2023-06-01 19:31:31      7.0      7.0    0.0\n",
       "3      N236012024 2023-06-01 19:31:32      7.0      7.0    0.0\n",
       "4      N236012024 2023-06-01 19:31:33      7.0      7.0    0.0\n",
       "...           ...                 ...      ...      ...    ...\n",
       "13467  N236012024 2023-06-01 23:15:56  25807.0  25081.0  726.0\n",
       "13468  N236012024 2023-06-01 23:15:57  25807.0  25081.0  726.0\n",
       "13469  N236012024 2023-06-01 23:15:58  25807.0  25081.0  726.0\n",
       "13470  N236012024 2023-06-01 23:15:59  25807.0  25081.0  726.0\n",
       "13471  N236012024 2023-06-01 23:16:00  25807.0  25081.0  726.0\n",
       "\n",
       "[13472 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시차 이동 예시 \n",
    "lag = 2 \n",
    "\n",
    "df = load_production(0) # cycletime 3.6 ~ 5.9초만 활용 \n",
    "df = df[(df['사출기 : 실적표시:사이클시간_Actual_v.:Cycle_time'] >=3)&(df['사출기 : 실적표시:사이클시간_Actual_v.:Cycle_time'] <6)]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# 검사수량 한정 시차 이동 \n",
    "count_shift = df[['투입수량','양품수량','불량수량']].shift(lag) # lag 0 --> 시차이동 X \n",
    "df[['투입수량','양품수량','불량수량']] = count_shift\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "df[['BatchName','생산시간','투입수량','양품수량','불량수량']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33ee8f1",
   "metadata": {},
   "source": [
    "#### 8.) CycleTime 4,5초에 해당하는 데이터 인덱스 부여 \n",
    "- Setting 값 제거 &  Actual 입력변수 기준 획일값 1차 제거 \n",
    "- 수량 증가량 0인 Index 부분행 제거 \n",
    "- Actual 입력변수 기준 획일값 2차 제거 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8734200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data No. 1  ==> Add CycleTime_Index   16764\n",
      "Data No. 2  ==> Add CycleTime_Index   17387\n",
      "Data No. 3  ==> Add CycleTime_Index   19469\n",
      "Data No. 4  ==> Add CycleTime_Index   17668\n",
      "Data No. 6  ==> Add CycleTime_Index   16993\n",
      "Data No. 7  ==> Add CycleTime_Index   17160\n",
      "Data No. 8  ==> Add CycleTime_Index   22786\n",
      "Data No. 9  ==> Add CycleTime_Index   17890\n",
      "Data No. 10  ==> Add CycleTime_Index   17392\n",
      "Data No. 11  ==> Add CycleTime_Index   20087\n",
      "Data No. 12  ==> Add CycleTime_Index   18068\n",
      "Data No. 13  ==> Add CycleTime_Index   18830\n",
      "Data No. 14  ==> Add CycleTime_Index   19534\n",
      "Data No. 16  ==> Add CycleTime_Index   17447\n",
      "Data No. 17  ==> Add CycleTime_Index   18911\n",
      "Data No. 18  ==> Add CycleTime_Index   17724\n",
      "Data No. 20  ==> Add CycleTime_Index   17804\n",
      "Data No. 21  ==> Add CycleTime_Index   25921\n",
      "Data No. 22  ==> Add CycleTime_Index   26532\n",
      "Data No. 23  ==> Add CycleTime_Index   19877\n",
      "Data No. 25  ==> Add CycleTime_Index   18627\n",
      "Data No. 26  ==> Add CycleTime_Index   19995\n",
      "Data No. 27  ==> Add CycleTime_Index   18003\n",
      "Data No. 28  ==> Add CycleTime_Index   17355\n",
      "Data No. 29  ==> Add CycleTime_Index   17684\n",
      "Data No. 30  ==> Add CycleTime_Index   18095\n",
      "Data No. 32  ==> Add CycleTime_Index   18726\n",
      "Data No. 33  ==> Add CycleTime_Index   18807\n",
      "Data No. 34  ==> Add CycleTime_Index   17636\n",
      "Data No. 35  ==> Add CycleTime_Index   17679\n",
      "Data No. 37  ==> Add CycleTime_Index   18224\n",
      "Data No. 38  ==> Add CycleTime_Index   16688\n",
      "Data No. 39  ==> Add CycleTime_Index   19093\n",
      "Data No. 40  ==> Add CycleTime_Index   25736\n",
      "\n",
      "\n",
      "Setting Values ==> 123\n",
      "Original Actual Values = 250   ==>  Cut Actual Values= 73\n"
     ]
    }
   ],
   "source": [
    "production = preprocess_production() # Setting값 제거 & 획일값 제거 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee3c034a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 1  N236012024  16433 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 2  N236022007  17107 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 3  N236022013  17397 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 4  N236062019  16962 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 6  N236072005  16609 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 7  N236072007  16772 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 8  N236072012  16681 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 9  N236072024  17335 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 10  N236132019  17274 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 11  N236132025  17341 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 12  N236132031  17253 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 13  N236142001  17519 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 14  N236142015  15503 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 16  N236142025  17345 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 17  N236142033  17178 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 18  N236152002  17362 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 20  N236152033  17319 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 21  N236162002  17263 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 22  N236162010  17268 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 23  N236162030  17955 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 25  N236172002  18072 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 26  N236172012  17729 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 27  N236172016  16881 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 28  N236172021  16831 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 29  N236172024  16977 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 30  N236182001  16993 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 32  N236182013  17430 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 33  N236192005  17339 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 34  N236192006  16884 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 35  N236192008  16723 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 37  N236192029  17761 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 38  N236202013  16456 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 39  N236222027  17375 행\n",
      "투입수량 증가하는 CycleTime_Index 식별 ==> Data No. 40  N236282012  17673 행\n"
     ]
    }
   ],
   "source": [
    "production_filtered = preprocess_filter() # 수량 증가량 0인 인덱스에 해당하는 부분행 제거 & 획일값 제거 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f93af603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(583000, 78)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "production_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63675acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(583000, 0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 남은 획일값 입력변수 확인 \n",
    "production_filtered[production_filtered.columns[8:].tolist()].loc[:,production_filtered[production_filtered.columns[8:].tolist()].nunique()==1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fb6cfe",
   "metadata": {},
   "source": [
    "#### 9.) Index별 Groupby \n",
    "- 각 CycleTime_Index당 파생변수 생성 [ Mean/Change_Detection ] \n",
    "- Groupby 이후 각 Index당 수량 증가량 8인 행 선택\n",
    "- 획일값 3차 탐지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "180ac9d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data No. 1  ==> Add Change Detection Column\n",
      "Data No. 2  ==> Add Change Detection Column\n",
      "Data No. 3  ==> Add Change Detection Column\n",
      "Data No. 4  ==> Add Change Detection Column\n",
      "Data No. 6  ==> Add Change Detection Column\n",
      "Data No. 7  ==> Add Change Detection Column\n",
      "Data No. 8  ==> Add Change Detection Column\n",
      "Data No. 9  ==> Add Change Detection Column\n",
      "Data No. 10  ==> Add Change Detection Column\n",
      "Data No. 11  ==> Add Change Detection Column\n",
      "Data No. 12  ==> Add Change Detection Column\n",
      "Data No. 13  ==> Add Change Detection Column\n",
      "Data No. 14  ==> Add Change Detection Column\n",
      "Data No. 16  ==> Add Change Detection Column\n",
      "Data No. 17  ==> Add Change Detection Column\n",
      "Data No. 18  ==> Add Change Detection Column\n",
      "Data No. 20  ==> Add Change Detection Column\n",
      "Data No. 21  ==> Add Change Detection Column\n",
      "Data No. 22  ==> Add Change Detection Column\n",
      "Data No. 23  ==> Add Change Detection Column\n",
      "Data No. 25  ==> Add Change Detection Column\n",
      "Data No. 26  ==> Add Change Detection Column\n",
      "Data No. 27  ==> Add Change Detection Column\n",
      "Data No. 28  ==> Add Change Detection Column\n",
      "Data No. 29  ==> Add Change Detection Column\n",
      "Data No. 30  ==> Add Change Detection Column\n",
      "Data No. 32  ==> Add Change Detection Column\n",
      "Data No. 33  ==> Add Change Detection Column\n",
      "Data No. 34  ==> Add Change Detection Column\n",
      "Data No. 35  ==> Add Change Detection Column\n",
      "Data No. 37  ==> Add Change Detection Column\n",
      "Data No. 38  ==> Add Change Detection Column\n",
      "Data No. 39  ==> Add Change Detection Column\n",
      "Data No. 40  ==> Add Change Detection Column\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for i in data_list:\n",
    "    production_sample = add_change_detection(i)\n",
    "    print('Data No.',i+1,' ==> Add Change Detection Column')\n",
    "    dfs.append(production_sample)   \n",
    "production_added = pd.concat(dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb55a7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(583000, 79)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "production_added.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb44452d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(583000, 0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 남은 획일값 입력변수 확인 \n",
    "production_added[production_added.columns[8:].tolist()].loc[:,production_added[production_added.columns[8:].tolist()].nunique()==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "090e5be5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data No. 1  ==> Groupby CycleTime_Index\n",
      "Data No. 2  ==> Groupby CycleTime_Index\n",
      "Data No. 3  ==> Groupby CycleTime_Index\n",
      "Data No. 4  ==> Groupby CycleTime_Index\n",
      "Data No. 6  ==> Groupby CycleTime_Index\n",
      "Data No. 7  ==> Groupby CycleTime_Index\n",
      "Data No. 8  ==> Groupby CycleTime_Index\n",
      "Data No. 9  ==> Groupby CycleTime_Index\n",
      "Data No. 10  ==> Groupby CycleTime_Index\n",
      "Data No. 11  ==> Groupby CycleTime_Index\n",
      "Data No. 12  ==> Groupby CycleTime_Index\n",
      "Data No. 13  ==> Groupby CycleTime_Index\n",
      "Data No. 14  ==> Groupby CycleTime_Index\n",
      "Data No. 16  ==> Groupby CycleTime_Index\n",
      "Data No. 17  ==> Groupby CycleTime_Index\n",
      "Data No. 18  ==> Groupby CycleTime_Index\n",
      "Data No. 20  ==> Groupby CycleTime_Index\n",
      "Data No. 21  ==> Groupby CycleTime_Index\n",
      "Data No. 22  ==> Groupby CycleTime_Index\n",
      "Data No. 23  ==> Groupby CycleTime_Index\n",
      "Data No. 25  ==> Groupby CycleTime_Index\n",
      "Data No. 26  ==> Groupby CycleTime_Index\n",
      "Data No. 27  ==> Groupby CycleTime_Index\n",
      "Data No. 28  ==> Groupby CycleTime_Index\n",
      "Data No. 29  ==> Groupby CycleTime_Index\n",
      "Data No. 30  ==> Groupby CycleTime_Index\n",
      "Data No. 32  ==> Groupby CycleTime_Index\n",
      "Data No. 33  ==> Groupby CycleTime_Index\n",
      "Data No. 34  ==> Groupby CycleTime_Index\n",
      "Data No. 35  ==> Groupby CycleTime_Index\n",
      "Data No. 37  ==> Groupby CycleTime_Index\n",
      "Data No. 38  ==> Groupby CycleTime_Index\n",
      "Data No. 39  ==> Groupby CycleTime_Index\n",
      "Data No. 40  ==> Groupby CycleTime_Index\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for i in data_list:\n",
    "    df_groupby = groupby(i)\n",
    "    dfs.append(df_groupby)\n",
    "    print('Data No.',i+1,' ==> Groupby CycleTime_Index') \n",
    "df_groupby_concat = pd.concat(dfs).reset_index(drop=True)\n",
    "df_groupby_concat = df_groupby_concat.drop(['사출기 : 실적표시:사이클시간_Actual_v.:Cycle_time_Mean'],axis=1)\n",
    "df_groupby_concat['Change_Detection'] = df_groupby_concat['Change_Detection'].replace({'False':0,'True':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb499720",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby_concat.to_csv('df_v2_lag2.csv',encoding='cp949',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
