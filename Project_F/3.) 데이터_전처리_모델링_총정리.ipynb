{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cae38d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cac7502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'CSV 사출데이터/'\n",
    "file_list = os.listdir(path)\n",
    "file_df = pd.DataFrame(file_list)\n",
    "black_list = [4,9,14,18,23,30,35]\n",
    "file_list = file_df[file_df.index.isin(black_list)== False][0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37ac2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for slide in tqdm(range(0,6)):\n",
    "    total_df = pd.DataFrame()\n",
    "    group_number = 0\n",
    "    for file in tqdm(file_list):\n",
    "        try : df = pd.read_csv(path+ file)\n",
    "        except: \n",
    "            df = pd.read_csv(path+file,encoding='CP949')\n",
    "            df.rename({df.columns[0]:'일시'},axis=1)   \n",
    "        df = df[(df.INM005_H_05_09_464 >=3)&(df.INM005_H_05_09_464 <5.8)].reset_index(drop=True)\n",
    "        df[['투입수량','양품수량','불량수량']] = df[['투입수량','양품수량','불량수량']].shift(slide)\n",
    "        df = df.iloc[slide:].reset_index(drop=True)\n",
    "        start = 1\n",
    "        integer = 0\n",
    "        decimal = 0\n",
    "        result = []\n",
    "        result_group_number = []\n",
    "        for n, i in enumerate(range(len(df))):\n",
    "            if start == 1:\n",
    "                integer, decimal_point = str(df.iloc[i].INM005_H_05_09_464).split('.')\n",
    "                integer, decimal_point = int(integer), float(decimal_point)\n",
    "                if decimal >= 1:\n",
    "                    decimal -= 1\n",
    "                    integer += 1\n",
    "                if n == 0:\n",
    "                    result_group_number.append(group_number)\n",
    "                    result.append(df.iloc[i])\n",
    "                    start += 1\n",
    "                    decimal = decimal+ decimal_point*0.1\n",
    "                else:\n",
    "                    result_group_number.append(group_number)\n",
    "                    group_number+=1\n",
    "                    start += 1\n",
    "                    result_group_number.append(group_number)\n",
    "                    result.append(df.iloc[i])\n",
    "                    result.append(df.iloc[i])\n",
    "                    decimal = decimal+ decimal_point*0.1\n",
    "            else:\n",
    "                result_group_number.append(group_number)\n",
    "                result.append(df.iloc[i])\n",
    "                start += 1\n",
    "                if start < integer: continue\n",
    "                else: start -= integer\n",
    "        df1 = pd.DataFrame(result, columns = df.columns)\n",
    "        df1['group'] = result_group_number\n",
    "        df1['투입수량'] = (df1['투입수량'] - df1['투입수량'].shift()).fillna(0)\n",
    "        df1['양품수량'] = (df1['양품수량'] - df1['양품수량'].shift()).fillna(0)\n",
    "        df1['불량수량'] = (df1['불량수량'] - df1['불량수량'].shift()).fillna(0)\n",
    "        df1 = df1[df1.group != group_number]\n",
    "        total_df = pd.concat([total_df,df1])\n",
    "    total_df.to_csv(str(slide)+'_total_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6a9cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for slide in range(6):\n",
    "    total_df = pd.read_csv(str(slide)+'_total_df.csv')\n",
    "    total_df = total_df.drop(['일시','Unnamed: 0','?쇱떆'],axis=1 )\n",
    "    drop_cols = [col for col in total_df.columns if total_df[col].nunique() ==1]\n",
    "    total_df = total_df.drop(drop_cols,axis=1)\n",
    "    nunique_cols = total_df.drop(['투입수량','양품수량','불량수량'],axis=1).groupby('group').nunique()\n",
    "    nunique_cols = [col for col in nunique_cols.columns if nunique_cols[col].nunique() == 1]\n",
    "    total_df = total_df.drop(nunique_cols, axis=1)\n",
    "    label_cols = ['투입수량','양품수량','불량수량']\n",
    "    label_df  = total_df[label_cols+['group']]\n",
    "    label_df= label_df.groupby('group').sum().reset_index()\n",
    "    unique_cols = total_df.drop(label_cols,axis=1)\n",
    "    unique_cols.groupby('group').nunique()['INM005_H_05_09_053'].value_counts()\n",
    "    unique_cols = unique_cols.groupby('group').nunique()\n",
    "    unique_cols = [col for col in unique_cols.columns if unique_cols[col].nunique() <2]\n",
    "    if len(unique_cols) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        total_df = total_df.drop(unique_cols,axis=1)\n",
    "        unique_df = pd.merge(total_df[unique_cols + ['group']]).groupby('group').mean().reset_index()\n",
    "        label_df = pd.merge(label_df, unique_df, on='group') \n",
    "    min_df = total_df.drop(label_cols,axis=1).groupby('group').max().reset_index()\n",
    "    max_df = total_df.drop(label_cols,axis=1).groupby('group').max().reset_index()\n",
    "    final_df = pd.merge(label_df, min_df, on='group')\n",
    "    final_df = pd.merge(final_df, max_df, on='group')\n",
    "    final_df = final_df[final_df.투입수량 == 8].reset_index(drop=True)\n",
    "    final_df = final_df.drop('group',axis=1)\n",
    "    drop_cols = [col for col in final_df.columns if final_df[col].nunique() ==1]\n",
    "    final_df = final_df.drop(drop_cols, axis=1)\n",
    "    final_df['label'] = final_df.불량수량.map(lambda x: 1 if x != 0 else 0)\n",
    "    final_df = final_df.drop(['양품수량','불량수량'],axis=1)\n",
    "    final_df.to_csv(str(slide)+'_final_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4808c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from optuna.samplers import TPESampler\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor, ExtraTreesRegressor, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from interpret.glassbox import ExplainableBoostingRegressor, ExplainableBoostingClassifier\n",
    "from interpret import show\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "class EarlyStoppingCallback(object):\n",
    "    \"\"\"Early stopping callback for Optuna.\"\"\"\n",
    "    def __init__(self, early_stopping_rounds: int, direction: str = \"minimize\") -> None:\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self._iter = 0\n",
    "        if direction == \"minimize\":\n",
    "            self._operator = operator.lt\n",
    "            self._score = np.inf\n",
    "        elif direction == \"maximize\":\n",
    "            self._operator = operator.gt\n",
    "            self._score = -np.inf\n",
    "        else:\n",
    "            ValueError(f\"invalid direction: {direction}\")\n",
    "    def __call__(self, study: optuna.Study, trial: optuna.Trial) -> None:\n",
    "        \"\"\"Do early stopping.\"\"\"\n",
    "        if self._operator(study.best_value, self._score):\n",
    "            self._iter = 0\n",
    "            self._score = study.best_value\n",
    "        else:\n",
    "            self._iter += 1\n",
    "        if self._iter >= self.early_stopping_rounds:\n",
    "            study.stop()\n",
    "\n",
    "def hist_create(trial):\n",
    "    param = {\n",
    "        'max_iter' : trial.suggest_int('max_iter',25,50),\n",
    "        'l2_regularization' : trial.suggest_float('l2_regularization', 0.1,2.5,step = 0.0000005),\n",
    "        'learning_rate' : trial.suggest_float('learning_rate', 0.1,2.5,step = 0.0005),\n",
    "        'max_depth' : trial.suggest_int('max_depth', 10, 20),\n",
    "        'max_bins' : trial.suggest_int('max_bins', 10, 255),\n",
    "        'min_samples_leaf' : trial.suggest_int('min_samples_leaf', 10, 20),\n",
    "        'max_leaf_nodes' : trial.suggest_int('max_leaf_nodes', 20, 35),\n",
    "        'random_state': trial.suggest_categorical('random_state', [2023]),\n",
    "    }\n",
    "    def get_model(param, REG):\n",
    "        if REG == True:model = HistGradientBoostingRegressor(**param)\n",
    "        else: model = HistGradientBoostingClassifier(**param)\n",
    "        return model\n",
    "    model = get_model(param, REG)\n",
    "    return model\n",
    "\n",
    "def ebm_create(trial):\n",
    "    param = {\n",
    "        'learning_rate' : trial.suggest_float('learning_rate', 0.1,2.5,step = 0.0005),\n",
    "        'max_leaves' : trial.suggest_int('max_leaves',3,20),\n",
    "        'random_state': trial.suggest_categorical('random_state', [2023])\n",
    "    }\n",
    "    def get_model(param, REG):\n",
    "        if REG == True:model = ExplainableBoostingRegressor(**param)\n",
    "        else: model = ExplainableBoostingClassifier(**param)\n",
    "        return model\n",
    "    model = get_model(param, REG)\n",
    "    return model\n",
    "\n",
    "def rf_create(trial):\n",
    "    param = {\n",
    "        'max_depth' : trial.suggest_int('max_depth', 5, 20),\n",
    "        'max_leaf_nodes' : trial.suggest_int('max_leaf_nodes', 2, 1000),\n",
    "        'n_estimators' :  trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'random_state': trial.suggest_categorical('random_state', [2023])\n",
    "    }\n",
    "    def get_model(param, REG):\n",
    "        if REG == True:model = RandomForestRegressor(**param)\n",
    "        else: model = RandomForestClassifier(**param)\n",
    "        return model\n",
    "    model = get_model(param, REG)\n",
    "    return model\n",
    "\n",
    "def ada_create(trial):\n",
    "    param = {\n",
    "        'n_estimators' : trial.suggest_int('n_estimators',10,80,step=2),\n",
    "        'learning_rate' :  trial.suggest_float('learning_rate', 0.1,2.5,step = 0.0000005),\n",
    "        'random_state': trial.suggest_categorical('random_state', [2023])\n",
    "    }\n",
    "    def get_model(param, REG):\n",
    "        if REG == True:model = AdaBoostRegressor(**param)\n",
    "        else: model = AdaBoostClassifier(**param)\n",
    "        return model\n",
    "    model = get_model(param, REG)\n",
    "\n",
    "    return model\n",
    "\n",
    "def cat_create(trial):\n",
    "    param = {\n",
    "#         \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n",
    "        'iterations' : trial.suggest_int('iterations', 5, 30),\n",
    "        'od_wait':trial.suggest_int('od_wait', 100, 500),\n",
    "        'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n",
    "#         'subsample': trial.suggest_uniform('subsample',0,1),\n",
    "        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "        'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,10),\n",
    "        'depth' : trial.suggest_int('depth', 3, 15),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,30),  \n",
    "        'task_type':\"CPU\",\n",
    "#         'colsample_bylevel' :  trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n",
    "        'random_state': trial.suggest_categorical('random_state', [2023]),\n",
    "\n",
    "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"])\n",
    "    }\n",
    "\n",
    "\n",
    "    def get_model(param, REG):\n",
    "        if REG == True:model = CatBoostRegressor(**param)\n",
    "        else: model = CatBoostClassifier(**param)\n",
    "        return model\n",
    "    model = get_model(param, REG)    \n",
    "    return model\n",
    "\n",
    "\n",
    "    def get_model(param, REG):\n",
    "        if REG == True:model = CatBoostRegressor(**param)\n",
    "        else: model = CatBoostClassifier(**param)\n",
    "        return model\n",
    "    model = get_model(param, REG)    \n",
    "    return model\n",
    "\n",
    "def ert_create(trial):\n",
    "    param = {\n",
    "        'n_estimators' : trial.suggest_int('n_estimators', 50, 120),\n",
    "        'max_depth' : trial.suggest_int('max_depth', 5, 16),\n",
    "        'max_leaf_nodes' : trial.suggest_int('max_leaf_nodes', 15, 25),\n",
    "        'random_state': trial.suggest_categorical('random_state', [2023])\n",
    "    }\n",
    "\n",
    "    def get_model(param, REG):\n",
    "        if REG == True:model = ExtraTreesRegressor(**param)\n",
    "        else: model = ExtraTreesClassifier(**param)\n",
    "        return model\n",
    "    model = get_model(param, REG)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def xgb_create(trial):\n",
    "    param = {\n",
    "        'n_estimators' : trial.suggest_int(\"n_estimators\", 20, 1000),\n",
    "        'max_depth' : trial.suggest_int('max_depth', 3, 20),\n",
    "        'learning_rate' : trial.suggest_uniform('learning_rate', 0.0001, 0.99),\n",
    "        'min_child_weight' :  trial.suggest_int('min_child_weight', 1, 300),\n",
    "        'tree_method':'gpu_hist',  #얘가 쓰는중\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-4, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-4, 10.0),\n",
    "        'random_state': trial.suggest_categorical('random_state', [2023])}\n",
    "    def get_model(param, REG):\n",
    "        if REG == True:model = XGBRegressor(**param)\n",
    "        else: model = XGBClassifier(**param)\n",
    "        return model\n",
    "    model = get_model(param, REG)\n",
    "    return model\n",
    "\n",
    "def tabnet_create(trial):\n",
    "    param = {\n",
    "        'mask_type' : trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"]),\n",
    "        'n_steps' : trial.suggest_int(\"n_steps\", 1, 3, step=1),\n",
    "        'gamma' : trial.suggest_float(\"gamma\", 1.0, 2.0, step=0.2),\n",
    "        'n_independent' : trial.suggest_int(\"n_independent\", 1, 5),\n",
    "        'n_shared' : trial.suggest_int(\"n_shared\", 1, 5),\n",
    "        'lambda_sparse' : trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True)}\n",
    "    \n",
    "    def get_model(param, REG):\n",
    "        if REG == True:model = TabNetRegressor(**param)\n",
    "        else: model = TabNetClassifier(**param)\n",
    "        return model\n",
    "    \n",
    "    model = get_model(param, REG)\n",
    "\n",
    "    return model\n",
    "\n",
    "def lgbm_create(trial):\n",
    "    param = {\n",
    "        'num_leaves': trial.suggest_int(\"num_leaves\", 100, 500),\n",
    "        'n_estimators' : trial.suggest_int(\"n_estimators\", 5, 1000),\n",
    "        'max_depth' : trial.suggest_int('max_depth', 3,20),\n",
    "        'min_child_samples' : trial.suggest_int('min_child_samples', 100, 1200),\n",
    "        'learning_rate' : trial.suggest_uniform('learning_rate', 0.0001, 0.99),\n",
    "        'min_data_in_leaf' : trial.suggest_int('min_data_in_leaf', 1, 1000),\n",
    "        'random_state': trial.suggest_categorical('random_state', [2023])\n",
    "    }\n",
    "\n",
    "    def get_model(param, REG):\n",
    "        if REG == True:model = LGBMRegressor(**param)\n",
    "        else: model = LGBMClassifier(**param)\n",
    "        return model\n",
    "    model = get_model(param, REG)\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    if model_name == 'xgb' :  model = xgb_create(trial) #2018\n",
    "    elif model_name == 'lgbm':  model = lgbm_create(trial) #2018\n",
    "    elif model_name == 'rf' : model = rf_create(trial)\n",
    "    elif model_name == 'ert' : model = ert_create(trial)\n",
    "    elif model_name == 'ada' : model = ada_create(trial) # 2009\n",
    "    elif model_name == 'cat' : model = cat_create(trial)\n",
    "    elif model_name == 'hist' : model = hist_create(trial) #2019\n",
    "    elif model_name == 'ebm' : model = ebm_create(trial) #2022\n",
    "    elif model_name == 'tab' : model = tabnet_create(trial) #2022\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    if REG == False: score = f1_score(preds, y_valid)\n",
    "    else: score = mean_absolute_error(preds, y_valid)\n",
    "    return score\n",
    "\n",
    "def get_model(model_name, best_params):\n",
    "    if REG == False:\n",
    "        if model_name == 'xgb' :  model = XGBClassifier(**best_params[model_name])\n",
    "        elif model_name == 'lgbm':  model = LGBMClassifier(**best_params[model_name])\n",
    "        elif model_name == 'rf' : model = RandomForestClassifier(**best_params[model_name])\n",
    "        elif model_name == 'ert' : model = ExtraTreesClassifier(**best_params[model_name])\n",
    "        elif model_name == 'ada' : model = AdaBoostClassifier(**best_params[model_name])\n",
    "        elif model_name == 'cat' : model = CatBoostClassifier(**best_params[model_name])\n",
    "        elif model_name == 'hist' : model = HistGradientBoostingClassifier(**best_params[model_name])\n",
    "        elif model_name == 'ebm' : model = ExplainableBoostingClassifier(**best_params[model_name])\n",
    "    else:\n",
    "        if model_name == 'xgb' :  model = XGBRegressor(**best_params[model_name])\n",
    "        elif model_name == 'lgbm':  model = LGBMRegressor(**best_params[model_name])\n",
    "        elif model_name == 'rf' : model = RandomForestRegressor(**best_params[model_name])\n",
    "        elif model_name == 'ert' : model = ExtraTreesRegressor(**best_params[model_name])\n",
    "        elif model_name == 'ada' : model = AdaBoostRegressor(**best_params[model_name])\n",
    "        elif model_name == 'cat' : model = CatBoostRegressor(**best_params[model_name])\n",
    "        elif model_name == 'hist' : model = HistGradientBoostingRegressor(**best_params[model_name])\n",
    "        elif model_name == 'ebm' : model = ExplainableBoostingRegressor(**best_params[model_name])\n",
    "        elif model_name == 'tab' : model = TabNetRegressor(**best_params[model_name])\n",
    "    return model\n",
    "\n",
    "def get_corr(df_anova,i):\n",
    "    lists = []\n",
    "    x = df_anova.corr()\n",
    "    x = x.reset_index()\n",
    "    col_list = x['index']\n",
    "    x.drop(['index'], axis=1, inplace=True)\n",
    "    columns = x.columns.drop(target)\n",
    "    for col in columns:\n",
    "        indexes = x[col][(abs(x[col]) > i) & (x[col] < 1)].index\n",
    "        if len(indexes) != 0:\n",
    "            max_index = x[x[target] == np.max(x[target][indexes])].index\n",
    "            indexes = indexes.drop(max_index)\n",
    "        for i in indexes:\n",
    "            lists.append(i)\n",
    "    final_list = []\n",
    "    for i in lists:\n",
    "        if i not in final_list:\n",
    "            final_list.append(i)\n",
    "    final_columns = x.drop(col_list[final_list], axis=1).columns\n",
    "    df_anova_corr = df_anova[final_columns].copy()\n",
    "    return df_anova_corr\n",
    "import operator\n",
    "\n",
    "\n",
    "def get_train(model_name):\n",
    "    sampler = TPESampler(seed=1000)\n",
    "    study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "    early_stopping = EarlyStoppingCallback(200, direction='maximize')\n",
    "    if( model_name == 'cat')|(model_name =='tab'):\n",
    "        early_stopping = EarlyStoppingCallback(50, direction='maximize')\n",
    "        study.optimize(objective, n_trials=200, callbacks = [early_stopping])#callbacks= [early_stopping]\n",
    "    else : study.optimize(objective, n_trials=1200, callbacks= [early_stopping])\n",
    "    best_params = {}\n",
    "    best_params[model_name] = study.best_params\n",
    "\n",
    "    score = study.best_value\n",
    "    model = get_model(model_name, best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, f'{model_name}_{i}.pkl')\n",
    "    return model_name, model, best_params[model_name], score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16bf0c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 'fix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9220ced3-8462-4bbc-a401-ebabee5c0583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "total_list1 = []\n",
    "import numpy as np\n",
    "for slide in range(6):\n",
    "    final_df = pd.read_csv(str(slide)+'_final_df.csv')\n",
    "    final_df.loc[final_df.drop('label',axis=1).drop_duplicates().index].reset_index(drop=True)\n",
    "    X_features = final_df.drop('label',axis=1)\n",
    "    y_target = final_df.label\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_features, y_target, test_size= 0.1 , shuffle = False)\n",
    "    REG = False\n",
    "    model_list = ['hist','rf','ebm','ada']\n",
    "    for model_name in model_list:\n",
    "        model_name, model, params, score = get_train(model_name)\n",
    "        preds = model.predict(X_valid)\n",
    "        total_list1.append([slide, model_name, params, score, accuracy_score(preds, y_valid)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c79a600e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1        2336\n",
       "0        1103\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_valid).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0aac020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_lag</th>\n",
       "      <th>model</th>\n",
       "      <th>estimator</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>xgb</td>\n",
       "      <td>{'n_estimators': 816, 'max_depth': 19, 'learni...</td>\n",
       "      <td>0.603482</td>\n",
       "      <td>0.530075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>{'num_leaves': 418, 'n_estimators': 70, 'max_d...</td>\n",
       "      <td>0.785927</td>\n",
       "      <td>0.750145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>xgb</td>\n",
       "      <td>{'n_estimators': 566, 'max_depth': 15, 'learni...</td>\n",
       "      <td>0.645880</td>\n",
       "      <td>0.540596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>{'num_leaves': 153, 'n_estimators': 34, 'max_d...</td>\n",
       "      <td>0.839639</td>\n",
       "      <td>0.808119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>xgb</td>\n",
       "      <td>{'n_estimators': 452, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.793500</td>\n",
       "      <td>0.746876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>{'num_leaves': 117, 'n_estimators': 76, 'max_d...</td>\n",
       "      <td>0.860578</td>\n",
       "      <td>0.824760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>xgb</td>\n",
       "      <td>{'n_estimators': 564, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.600347</td>\n",
       "      <td>0.561110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>{'num_leaves': 382, 'n_estimators': 7, 'max_de...</td>\n",
       "      <td>0.790991</td>\n",
       "      <td>0.750650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>xgb</td>\n",
       "      <td>{'n_estimators': 911, 'max_depth': 4, 'learnin...</td>\n",
       "      <td>0.642781</td>\n",
       "      <td>0.466609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>{'num_leaves': 500, 'n_estimators': 63, 'max_d...</td>\n",
       "      <td>0.697802</td>\n",
       "      <td>0.651698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>xgb</td>\n",
       "      <td>{'n_estimators': 632, 'max_depth': 15, 'learni...</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.564408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>{'num_leaves': 269, 'n_estimators': 80, 'max_d...</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.659785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    time_lag model                                          estimator  \\\n",
       "0          0   xgb  {'n_estimators': 816, 'max_depth': 19, 'learni...   \n",
       "1          0  lgbm  {'num_leaves': 418, 'n_estimators': 70, 'max_d...   \n",
       "2          1   xgb  {'n_estimators': 566, 'max_depth': 15, 'learni...   \n",
       "3          1  lgbm  {'num_leaves': 153, 'n_estimators': 34, 'max_d...   \n",
       "4          2   xgb  {'n_estimators': 452, 'max_depth': 3, 'learnin...   \n",
       "5          2  lgbm  {'num_leaves': 117, 'n_estimators': 76, 'max_d...   \n",
       "6          3   xgb  {'n_estimators': 564, 'max_depth': 5, 'learnin...   \n",
       "7          3  lgbm  {'num_leaves': 382, 'n_estimators': 7, 'max_de...   \n",
       "8          4   xgb  {'n_estimators': 911, 'max_depth': 4, 'learnin...   \n",
       "9          4  lgbm  {'num_leaves': 500, 'n_estimators': 63, 'max_d...   \n",
       "10         5   xgb  {'n_estimators': 632, 'max_depth': 15, 'learni...   \n",
       "11         5  lgbm  {'num_leaves': 269, 'n_estimators': 80, 'max_d...   \n",
       "\n",
       "         acc  f1_score  \n",
       "0   0.603482  0.530075  \n",
       "1   0.785927  0.750145  \n",
       "2   0.645880  0.540596  \n",
       "3   0.839639  0.808119  \n",
       "4   0.793500  0.746876  \n",
       "5   0.860578  0.824760  \n",
       "6   0.600347  0.561110  \n",
       "7   0.790991  0.750650  \n",
       "8   0.642781  0.466609  \n",
       "9   0.697802  0.651698  \n",
       "10  0.644860  0.564408  \n",
       "11  0.682927  0.659785  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(total_list1,columns = ['time_lag','model','estimator','acc','f1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73a49797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  'cat',\n",
       "  {'iterations': 26,\n",
       "   'od_wait': 301,\n",
       "   'reg_lambda': 91.9164297936471,\n",
       "   'bagging_temperature': 0.03282775426654037,\n",
       "   'learning_rate': 0.2768818655458132,\n",
       "   'leaf_estimation_iterations': 8,\n",
       "   'depth': 4,\n",
       "   'min_data_in_leaf': 12,\n",
       "   'random_state': 2023,\n",
       "   'boosting_type': 'Plain'},\n",
       "  0.6978494623655914,\n",
       "  0.6749566223250434],\n",
       " [1,\n",
       "  'cat',\n",
       "  {'iterations': 28,\n",
       "   'od_wait': 305,\n",
       "   'reg_lambda': 75.57773189920198,\n",
       "   'bagging_temperature': 0.05875324626145144,\n",
       "   'learning_rate': 0.24151378977476057,\n",
       "   'leaf_estimation_iterations': 5,\n",
       "   'depth': 4,\n",
       "   'min_data_in_leaf': 3,\n",
       "   'random_state': 2023,\n",
       "   'boosting_type': 'Plain'},\n",
       "  0.6179302045728039,\n",
       "  0.6290887850467289],\n",
       " [2,\n",
       "  'cat',\n",
       "  {'iterations': 27,\n",
       "   'od_wait': 377,\n",
       "   'reg_lambda': 84.32089262047836,\n",
       "   'bagging_temperature': 2.356149703515959,\n",
       "   'learning_rate': 0.2952783548580561,\n",
       "   'leaf_estimation_iterations': 10,\n",
       "   'depth': 3,\n",
       "   'min_data_in_leaf': 12,\n",
       "   'random_state': 2023,\n",
       "   'boosting_type': 'Plain'},\n",
       "  0.705503355704698,\n",
       "  0.6811973263586166],\n",
       " [3,\n",
       "  'cat',\n",
       "  {'iterations': 23,\n",
       "   'od_wait': 132,\n",
       "   'reg_lambda': 99.57874848447284,\n",
       "   'bagging_temperature': 0.4454855255608423,\n",
       "   'learning_rate': 0.23496465299703828,\n",
       "   'leaf_estimation_iterations': 3,\n",
       "   'depth': 3,\n",
       "   'min_data_in_leaf': 10,\n",
       "   'random_state': 2023,\n",
       "   'boosting_type': 'Plain'},\n",
       "  0.5346658338538414,\n",
       "  0.569488587113551],\n",
       " [4,\n",
       "  'cat',\n",
       "  {'iterations': 27,\n",
       "   'od_wait': 150,\n",
       "   'reg_lambda': 38.78826042189065,\n",
       "   'bagging_temperature': 0.1178318322496895,\n",
       "   'learning_rate': 0.2756414443203604,\n",
       "   'leaf_estimation_iterations': 10,\n",
       "   'depth': 12,\n",
       "   'min_data_in_leaf': 3,\n",
       "   'random_state': 2023,\n",
       "   'boosting_type': 'Ordered'},\n",
       "  0.5752718946765885,\n",
       "  0.5728267127230858],\n",
       " [5,\n",
       "  'cat',\n",
       "  {'iterations': 29,\n",
       "   'od_wait': 242,\n",
       "   'reg_lambda': 6.708890605929673,\n",
       "   'bagging_temperature': 0.051923896780585864,\n",
       "   'learning_rate': 0.27273716292092676,\n",
       "   'leaf_estimation_iterations': 6,\n",
       "   'depth': 3,\n",
       "   'min_data_in_leaf': 15,\n",
       "   'random_state': 2023,\n",
       "   'boosting_type': 'Plain'},\n",
       "  0.7659137577002053,\n",
       "  0.7348066298342542]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c2de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5652d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
